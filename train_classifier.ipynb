{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our Philosophical Document Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\Desktop\\UCSD\\256\\philosophical_oracle\\philosophy_oracle\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import loader\n",
    "import models\n",
    "import utility\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_category_mapping, category_label_mapping = loader.load_labeling_mappings()\n",
    "filename_label_mapping = filename_category_mapping\n",
    "for key, value in filename_label_mapping.items():\n",
    "    filename_label_mapping[key] = int(category_label_mapping[value])\n",
    "\n",
    "loader_params = {\n",
    "    \"num_labels\": len(category_label_mapping),\n",
    "    \"batch_size\": 4,\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 100,\n",
    "    \"balance_multiplier\": 1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.945   |   0.150   ||   1.924   |  0.283  \n",
      " 2 / 10 ||    1.922   |   0.162   ||   1.913   |  0.283  \n",
      " 3 / 10 ||    1.868   |   0.359   ||   1.915   |  0.208  \n",
      " 4 / 10 ||    1.756   |   0.503   ||   1.919   |  0.075  \n",
      " 5 / 10 ||    1.518   |   0.599   ||   1.912   |  0.132  \n",
      " 6 / 10 ||    1.254   |   0.677   ||   1.952   |  0.245  \n",
      " 7 / 10 ||    1.011   |   0.731   ||   2.034   |  0.226  \n",
      " 8 / 10 ||    0.811   |   0.784   ||   2.131   |  0.208  \n",
      " 9 / 10 ||    0.733   |   0.766   ||   2.204   |  0.189  \n",
      " 10/ 10 ||    0.567   |   0.868   ||   2.243   |  0.226  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.935   |   0.185   ||   1.926   |  0.189  \n",
      " 2 / 10 ||    1.841   |   0.342   ||   1.863   |  0.208  \n",
      " 3 / 10 ||    1.515   |   0.581   ||   1.780   |  0.453  \n",
      " 4 / 10 ||    1.017   |   0.738   ||   1.612   |  0.396  \n",
      " 5 / 10 ||    0.688   |   0.838   ||   1.623   |  0.340  \n",
      " 6 / 10 ||    0.545   |   0.838   ||   1.546   |  0.377  \n",
      " 7 / 10 ||    0.403   |   0.892   ||   1.523   |  0.415  \n",
      " 8 / 10 ||    0.349   |   0.927   ||   1.609   |  0.358  \n",
      " 9 / 10 ||    0.268   |   0.931   ||   1.786   |  0.434  \n",
      " 10/ 10 ||    0.236   |   0.946   ||   1.726   |  0.377  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.4 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.945   |   0.186   ||   1.930   |  0.151  \n",
      " 2 / 10 ||    1.927   |   0.182   ||   1.917   |  0.151  \n",
      " 3 / 10 ||    1.879   |   0.267   ||   1.894   |  0.245  \n",
      " 4 / 10 ||    1.768   |   0.398   ||   1.809   |  0.264  \n",
      " 5 / 10 ||    1.633   |   0.415   ||   1.751   |  0.283  \n",
      " 6 / 10 ||    1.432   |   0.517   ||   1.689   |  0.264  \n",
      " 7 / 10 ||    1.298   |   0.542   ||   1.651   |  0.283  \n",
      " 8 / 10 ||    1.187   |   0.585   ||   1.542   |  0.358  \n",
      " 9 / 10 ||    1.114   |   0.606   ||   1.445   |  0.415  \n",
      " 10/ 10 ||    1.052   |   0.678   ||   1.450   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 2.2 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.902   |   0.256   ||   1.901   |  0.340  \n",
      " 2 / 10 ||    1.421   |   0.574   ||   1.766   |  0.321  \n",
      " 3 / 10 ||    0.933   |   0.706   ||   1.742   |  0.321  \n",
      " 4 / 10 ||    0.707   |   0.771   ||   1.873   |  0.321  \n",
      " 5 / 10 ||    0.592   |   0.800   ||   1.758   |  0.340  \n",
      " 6 / 10 ||    0.459   |   0.861   ||   1.902   |  0.321  \n",
      " 7 / 10 ||    0.381   |   0.889   ||   2.144   |  0.340  \n",
      " 8 / 10 ||    0.308   |   0.915   ||   2.148   |  0.302  \n",
      " 9 / 10 ||    0.253   |   0.932   ||   2.339   |  0.283  \n",
      " 10/ 10 ||    0.222   |   0.934   ||   2.557   |  0.283  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.923   |   0.237   ||   1.905   |  0.321  \n",
      " 2 / 10 ||    1.638   |   0.452   ||   1.653   |  0.377  \n",
      " 3 / 10 ||    1.189   |   0.623   ||   1.527   |  0.396  \n",
      " 4 / 10 ||    0.984   |   0.659   ||   1.481   |  0.434  \n",
      " 5 / 10 ||    0.806   |   0.708   ||   1.440   |  0.453  \n",
      " 6 / 10 ||    0.704   |   0.768   ||   1.646   |  0.453  \n",
      " 7 / 10 ||    0.633   |   0.787   ||   1.645   |  0.453  \n",
      " 8 / 10 ||    0.567   |   0.812   ||   1.602   |  0.415  \n",
      " 9 / 10 ||    0.517   |   0.834   ||   1.668   |  0.434  \n",
      " 10/ 10 ||    0.497   |   0.834   ||   1.881   |  0.396  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.836   |   0.309   ||   1.872   |  0.208  \n",
      " 2 / 10 ||    1.224   |   0.574   ||   1.819   |  0.340  \n",
      " 3 / 10 ||    0.908   |   0.696   ||   1.946   |  0.283  \n",
      " 4 / 10 ||    0.734   |   0.754   ||   2.008   |  0.415  \n",
      " 5 / 10 ||    0.617   |   0.805   ||   1.911   |  0.358  \n",
      " 6 / 10 ||    0.523   |   0.831   ||   1.982   |  0.377  \n",
      " 7 / 10 ||    0.467   |   0.857   ||   1.988   |  0.396  \n",
      " 8 / 10 ||    0.402   |   0.870   ||   2.108   |  0.377  \n",
      " 9 / 10 ||    0.354   |   0.894   ||   2.175   |  0.358  \n",
      " 10/ 10 ||    0.317   |   0.902   ||   2.307   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.4 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.951   |   0.150   ||   1.927   |  0.283  \n",
      " 2 / 10 ||    1.920   |   0.162   ||   1.914   |  0.283  \n",
      " 3 / 10 ||    1.864   |   0.329   ||   1.912   |  0.245  \n",
      " 4 / 10 ||    1.744   |   0.509   ||   1.897   |  0.226  \n",
      " 5 / 10 ||    1.523   |   0.533   ||   1.856   |  0.283  \n",
      " 6 / 10 ||    1.286   |   0.653   ||   1.838   |  0.170  \n",
      " 7 / 10 ||    1.029   |   0.665   ||   1.909   |  0.189  \n",
      " 8 / 10 ||    0.910   |   0.719   ||   1.897   |  0.245  \n",
      " 9 / 10 ||    0.795   |   0.743   ||   1.945   |  0.264  \n",
      " 10/ 10 ||    0.614   |   0.844   ||   2.014   |  0.264  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.928   |   0.238   ||   1.945   |  0.189  \n",
      " 2 / 10 ||    1.815   |   0.523   ||   1.900   |  0.094  \n",
      " 3 / 10 ||    1.473   |   0.642   ||   1.769   |  0.283  \n",
      " 4 / 10 ||    0.940   |   0.815   ||   1.639   |  0.396  \n",
      " 5 / 10 ||    0.617   |   0.865   ||   1.563   |  0.396  \n",
      " 6 / 10 ||    0.435   |   0.912   ||   1.702   |  0.358  \n",
      " 7 / 10 ||    0.330   |   0.938   ||   1.504   |  0.434  \n",
      " 8 / 10 ||    0.290   |   0.915   ||   1.755   |  0.396  \n",
      " 9 / 10 ||    0.208   |   0.954   ||   1.541   |  0.396  \n",
      " 10/ 10 ||    0.224   |   0.950   ||   1.562   |  0.434  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.9 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.950   |   0.127   ||   1.940   |  0.151  \n",
      " 2 / 10 ||    1.934   |   0.195   ||   1.928   |  0.245  \n",
      " 3 / 10 ||    1.897   |   0.263   ||   1.895   |  0.302  \n",
      " 4 / 10 ||    1.803   |   0.364   ||   1.828   |  0.245  \n",
      " 5 / 10 ||    1.681   |   0.398   ||   1.736   |  0.283  \n",
      " 6 / 10 ||    1.514   |   0.462   ||   1.611   |  0.340  \n",
      " 7 / 10 ||    1.400   |   0.483   ||   1.619   |  0.358  \n",
      " 8 / 10 ||    1.247   |   0.559   ||   1.575   |  0.340  \n",
      " 9 / 10 ||    1.182   |   0.627   ||   1.455   |  0.377  \n",
      " 10/ 10 ||    1.064   |   0.619   ||   1.571   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.5 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.894   |   0.276   ||   1.939   |  0.245  \n",
      " 2 / 10 ||    1.372   |   0.545   ||   1.846   |  0.302  \n",
      " 3 / 10 ||    0.989   |   0.681   ||   1.848   |  0.321  \n",
      " 4 / 10 ||    0.727   |   0.765   ||   1.885   |  0.302  \n",
      " 5 / 10 ||    0.604   |   0.805   ||   2.096   |  0.302  \n",
      " 6 / 10 ||    0.505   |   0.834   ||   2.180   |  0.302  \n",
      " 7 / 10 ||    0.429   |   0.852   ||   2.183   |  0.302  \n",
      " 8 / 10 ||    0.373   |   0.892   ||   2.167   |  0.321  \n",
      " 9 / 10 ||    0.299   |   0.911   ||   2.295   |  0.340  \n",
      " 10/ 10 ||    0.264   |   0.921   ||   2.554   |  0.302  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.7 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.923   |   0.247   ||   1.917   |  0.321  \n",
      " 2 / 10 ||    1.677   |   0.508   ||   1.712   |  0.415  \n",
      " 3 / 10 ||    1.171   |   0.638   ||   1.456   |  0.453  \n",
      " 4 / 10 ||    0.933   |   0.689   ||   1.287   |  0.528  \n",
      " 5 / 10 ||    0.774   |   0.748   ||   1.400   |  0.509  \n",
      " 6 / 10 ||    0.693   |   0.766   ||   1.336   |  0.528  \n",
      " 7 / 10 ||    0.642   |   0.770   ||   1.396   |  0.509  \n",
      " 8 / 10 ||    0.542   |   0.842   ||   1.576   |  0.491  \n",
      " 9 / 10 ||    0.490   |   0.836   ||   1.446   |  0.509  \n",
      " 10/ 10 ||    0.435   |   0.876   ||   1.723   |  0.491  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 12.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.5 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.838   |   0.317   ||   1.900   |  0.189  \n",
      " 2 / 10 ||    1.281   |   0.543   ||   1.823   |  0.302  \n",
      " 3 / 10 ||    0.962   |   0.694   ||   1.802   |  0.358  \n",
      " 4 / 10 ||    0.754   |   0.760   ||   1.731   |  0.396  \n",
      " 5 / 10 ||    0.605   |   0.808   ||   1.762   |  0.396  \n",
      " 6 / 10 ||    0.508   |   0.835   ||   1.947   |  0.396  \n",
      " 7 / 10 ||    0.458   |   0.850   ||   1.824   |  0.396  \n",
      " 8 / 10 ||    0.363   |   0.882   ||   1.895   |  0.396  \n",
      " 9 / 10 ||    0.377   |   0.877   ||   2.073   |  0.396  \n",
      " 10/ 10 ||    0.307   |   0.905   ||   2.186   |  0.377  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 11.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.954   |   0.144   ||   1.934   |  0.075  \n",
      " 2 / 10 ||    1.924   |   0.251   ||   1.933   |  0.283  \n",
      " 3 / 10 ||    1.856   |   0.413   ||   1.899   |  0.264  \n",
      " 4 / 10 ||    1.685   |   0.449   ||   1.884   |  0.208  \n",
      " 5 / 10 ||    1.486   |   0.497   ||   1.874   |  0.132  \n",
      " 6 / 10 ||    1.283   |   0.575   ||   1.896   |  0.170  \n",
      " 7 / 10 ||    1.145   |   0.611   ||   1.908   |  0.189  \n",
      " 8 / 10 ||    0.989   |   0.689   ||   1.951   |  0.302  \n",
      " 9 / 10 ||    0.862   |   0.707   ||   2.035   |  0.340  \n",
      " 10/ 10 ||    0.781   |   0.784   ||   2.120   |  0.264  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.5 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.937   |   0.188   ||   1.944   |  0.189  \n",
      " 2 / 10 ||    1.843   |   0.396   ||   1.888   |  0.434  \n",
      " 3 / 10 ||    1.498   |   0.631   ||   1.739   |  0.358  \n",
      " 4 / 10 ||    1.054   |   0.681   ||   1.584   |  0.415  \n",
      " 5 / 10 ||    0.753   |   0.788   ||   1.463   |  0.434  \n",
      " 6 / 10 ||    0.575   |   0.842   ||   1.510   |  0.434  \n",
      " 7 / 10 ||    0.469   |   0.877   ||   1.459   |  0.377  \n",
      " 8 / 10 ||    0.377   |   0.904   ||   1.432   |  0.415  \n",
      " 9 / 10 ||    0.334   |   0.904   ||   1.458   |  0.321  \n",
      " 10/ 10 ||    0.269   |   0.935   ||   1.564   |  0.358  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.946   |   0.169   ||   1.962   |  0.151  \n",
      " 2 / 10 ||    1.933   |   0.165   ||   1.933   |  0.151  \n",
      " 3 / 10 ||    1.889   |   0.225   ||   1.885   |  0.264  \n",
      " 4 / 10 ||    1.798   |   0.381   ||   1.770   |  0.245  \n",
      " 5 / 10 ||    1.634   |   0.432   ||   1.687   |  0.302  \n",
      " 6 / 10 ||    1.502   |   0.445   ||   1.642   |  0.340  \n",
      " 7 / 10 ||    1.401   |   0.475   ||   1.555   |  0.302  \n",
      " 8 / 10 ||    1.236   |   0.555   ||   1.556   |  0.377  \n",
      " 9 / 10 ||    1.158   |   0.627   ||   1.542   |  0.358  \n",
      " 10/ 10 ||    1.071   |   0.661   ||   1.588   |  0.472  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.876   |   0.339   ||   1.881   |  0.170  \n",
      " 2 / 10 ||    1.361   |   0.561   ||   1.791   |  0.283  \n",
      " 3 / 10 ||    0.990   |   0.679   ||   1.858   |  0.283  \n",
      " 4 / 10 ||    0.742   |   0.761   ||   1.934   |  0.321  \n",
      " 5 / 10 ||    0.573   |   0.811   ||   2.011   |  0.358  \n",
      " 6 / 10 ||    0.509   |   0.848   ||   1.958   |  0.321  \n",
      " 7 / 10 ||    0.415   |   0.890   ||   2.244   |  0.340  \n",
      " 8 / 10 ||    0.341   |   0.906   ||   2.204   |  0.340  \n",
      " 9 / 10 ||    0.290   |   0.913   ||   2.155   |  0.321  \n",
      " 10/ 10 ||    0.239   |   0.934   ||   2.322   |  0.321  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.7 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.4 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.930   |   0.190   ||   1.921   |  0.302  \n",
      " 2 / 10 ||    1.687   |   0.516   ||   1.714   |  0.434  \n",
      " 3 / 10 ||    1.214   |   0.605   ||   1.443   |  0.453  \n",
      " 4 / 10 ||    0.905   |   0.695   ||   1.461   |  0.415  \n",
      " 5 / 10 ||    0.782   |   0.740   ||   1.398   |  0.472  \n",
      " 6 / 10 ||    0.707   |   0.757   ||   1.447   |  0.453  \n",
      " 7 / 10 ||    0.635   |   0.782   ||   1.412   |  0.509  \n",
      " 8 / 10 ||    0.537   |   0.814   ||   1.448   |  0.472  \n",
      " 9 / 10 ||    0.554   |   0.829   ||   1.690   |  0.453  \n",
      " 10/ 10 ||    0.485   |   0.846   ||   1.682   |  0.434  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.1 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.850   |   0.312   ||   1.849   |  0.321  \n",
      " 2 / 10 ||    1.234   |   0.606   ||   1.777   |  0.340  \n",
      " 3 / 10 ||    0.904   |   0.689   ||   1.911   |  0.377  \n",
      " 4 / 10 ||    0.722   |   0.752   ||   1.777   |  0.396  \n",
      " 5 / 10 ||    0.592   |   0.816   ||   1.943   |  0.396  \n",
      " 6 / 10 ||    0.520   |   0.835   ||   1.871   |  0.358  \n",
      " 7 / 10 ||    0.428   |   0.880   ||   2.012   |  0.377  \n",
      " 8 / 10 ||    0.385   |   0.876   ||   2.119   |  0.358  \n",
      " 9 / 10 ||    0.327   |   0.911   ||   2.264   |  0.321  \n",
      " 10/ 10 ||    0.295   |   0.905   ||   2.157   |  0.340  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.947   |   0.150   ||   1.922   |  0.283  \n",
      " 2 / 10 ||    1.932   |   0.192   ||   1.909   |  0.283  \n",
      " 3 / 10 ||    1.887   |   0.251   ||   1.909   |  0.226  \n",
      " 4 / 10 ||    1.782   |   0.347   ||   1.909   |  0.151  \n",
      " 5 / 10 ||    1.596   |   0.467   ||   1.903   |  0.151  \n",
      " 6 / 10 ||    1.360   |   0.563   ||   1.946   |  0.151  \n",
      " 7 / 10 ||    1.133   |   0.677   ||   1.980   |  0.264  \n",
      " 8 / 10 ||    0.910   |   0.737   ||   2.048   |  0.283  \n",
      " 9 / 10 ||    0.764   |   0.814   ||   2.082   |  0.226  \n",
      " 10/ 10 ||    0.628   |   0.844   ||   2.075   |  0.283  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.925   |   0.185   ||   1.919   |  0.396  \n",
      " 2 / 10 ||    1.776   |   0.442   ||   1.815   |  0.453  \n",
      " 3 / 10 ||    1.380   |   0.638   ||   1.675   |  0.491  \n",
      " 4 / 10 ||    0.933   |   0.777   ||   1.657   |  0.377  \n",
      " 5 / 10 ||    0.646   |   0.823   ||   1.655   |  0.226  \n",
      " 6 / 10 ||    0.489   |   0.881   ||   1.761   |  0.208  \n",
      " 7 / 10 ||    0.410   |   0.888   ||   1.892   |  0.321  \n",
      " 8 / 10 ||    0.336   |   0.904   ||   1.772   |  0.302  \n",
      " 9 / 10 ||    0.273   |   0.950   ||   1.945   |  0.340  \n",
      " 10/ 10 ||    0.210   |   0.946   ||   1.866   |  0.283  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 2.5 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.948   |   0.144   ||   1.983   |  0.075  \n",
      " 2 / 10 ||    1.932   |   0.161   ||   1.970   |  0.075  \n",
      " 3 / 10 ||    1.901   |   0.254   ||   1.926   |  0.264  \n",
      " 4 / 10 ||    1.833   |   0.360   ||   1.865   |  0.321  \n",
      " 5 / 10 ||    1.714   |   0.436   ||   1.801   |  0.226  \n",
      " 6 / 10 ||    1.504   |   0.487   ||   1.689   |  0.377  \n",
      " 7 / 10 ||    1.430   |   0.458   ||   1.611   |  0.283  \n",
      " 8 / 10 ||    1.289   |   0.576   ||   1.468   |  0.340  \n",
      " 9 / 10 ||    1.195   |   0.636   ||   1.533   |  0.358  \n",
      " 10/ 10 ||    1.123   |   0.606   ||   1.526   |  0.434  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.4 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.901   |   0.276   ||   1.904   |  0.321  \n",
      " 2 / 10 ||    1.458   |   0.516   ||   1.804   |  0.208  \n",
      " 3 / 10 ||    0.984   |   0.671   ||   1.925   |  0.340  \n",
      " 4 / 10 ||    0.757   |   0.761   ||   1.835   |  0.302  \n",
      " 5 / 10 ||    0.603   |   0.802   ||   1.835   |  0.302  \n",
      " 6 / 10 ||    0.491   |   0.853   ||   1.896   |  0.302  \n",
      " 7 / 10 ||    0.389   |   0.885   ||   1.982   |  0.245  \n",
      " 8 / 10 ||    0.349   |   0.884   ||   1.982   |  0.302  \n",
      " 9 / 10 ||    0.280   |   0.921   ||   2.130   |  0.340  \n",
      " 10/ 10 ||    0.274   |   0.918   ||   2.078   |  0.321  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.7 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.929   |   0.218   ||   1.928   |  0.170  \n",
      " 2 / 10 ||    1.694   |   0.431   ||   1.666   |  0.434  \n",
      " 3 / 10 ||    1.218   |   0.614   ||   1.417   |  0.434  \n",
      " 4 / 10 ||    0.933   |   0.706   ||   1.380   |  0.434  \n",
      " 5 / 10 ||    0.785   |   0.742   ||   1.370   |  0.415  \n",
      " 6 / 10 ||    0.693   |   0.755   ||   1.436   |  0.453  \n",
      " 7 / 10 ||    0.584   |   0.814   ||   1.653   |  0.472  \n",
      " 8 / 10 ||    0.528   |   0.812   ||   1.654   |  0.434  \n",
      " 9 / 10 ||    0.502   |   0.849   ||   1.532   |  0.453  \n",
      " 10/ 10 ||    0.465   |   0.846   ||   1.682   |  0.434  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.822   |   0.305   ||   1.878   |  0.283  \n",
      " 2 / 10 ||    1.223   |   0.581   ||   1.940   |  0.340  \n",
      " 3 / 10 ||    0.900   |   0.720   ||   1.842   |  0.340  \n",
      " 4 / 10 ||    0.712   |   0.768   ||   1.983   |  0.245  \n",
      " 5 / 10 ||    0.574   |   0.811   ||   1.981   |  0.358  \n",
      " 6 / 10 ||    0.464   |   0.854   ||   2.114   |  0.340  \n",
      " 7 / 10 ||    0.426   |   0.866   ||   2.172   |  0.396  \n",
      " 8 / 10 ||    0.365   |   0.889   ||   2.027   |  0.377  \n",
      " 9 / 10 ||    0.346   |   0.892   ||   2.225   |  0.358  \n",
      " 10/ 10 ||    0.306   |   0.904   ||   2.140   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.946   |   0.174   ||   1.952   |  0.113  \n",
      " 2 / 10 ||    1.916   |   0.281   ||   1.939   |  0.170  \n",
      " 3 / 10 ||    1.856   |   0.485   ||   1.887   |  0.340  \n",
      " 4 / 10 ||    1.727   |   0.461   ||   1.863   |  0.226  \n",
      " 5 / 10 ||    1.496   |   0.563   ||   1.815   |  0.245  \n",
      " 6 / 10 ||    1.242   |   0.611   ||   1.785   |  0.264  \n",
      " 7 / 10 ||    1.119   |   0.683   ||   1.865   |  0.245  \n",
      " 8 / 10 ||    0.930   |   0.737   ||   1.863   |  0.245  \n",
      " 9 / 10 ||    0.797   |   0.760   ||   1.811   |  0.340  \n",
      " 10/ 10 ||    0.674   |   0.802   ||   1.920   |  0.340  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.924   |   0.208   ||   1.937   |  0.170  \n",
      " 2 / 10 ||    1.792   |   0.573   ||   1.843   |  0.358  \n",
      " 3 / 10 ||    1.414   |   0.665   ||   1.785   |  0.377  \n",
      " 4 / 10 ||    0.949   |   0.742   ||   1.672   |  0.264  \n",
      " 5 / 10 ||    0.605   |   0.877   ||   1.661   |  0.264  \n",
      " 6 / 10 ||    0.489   |   0.896   ||   1.746   |  0.302  \n",
      " 7 / 10 ||    0.368   |   0.915   ||   1.830   |  0.264  \n",
      " 8 / 10 ||    0.261   |   0.954   ||   1.829   |  0.321  \n",
      " 9 / 10 ||    0.270   |   0.927   ||   1.985   |  0.302  \n",
      " 10/ 10 ||    0.213   |   0.950   ||   1.826   |  0.377  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.949   |   0.140   ||   1.944   |  0.170  \n",
      " 2 / 10 ||    1.931   |   0.225   ||   1.940   |  0.132  \n",
      " 3 / 10 ||    1.909   |   0.186   ||   1.914   |  0.264  \n",
      " 4 / 10 ||    1.845   |   0.369   ||   1.851   |  0.264  \n",
      " 5 / 10 ||    1.691   |   0.436   ||   1.768   |  0.264  \n",
      " 6 / 10 ||    1.511   |   0.441   ||   1.680   |  0.283  \n",
      " 7 / 10 ||    1.352   |   0.483   ||   1.571   |  0.358  \n",
      " 8 / 10 ||    1.219   |   0.576   ||   1.582   |  0.340  \n",
      " 9 / 10 ||    1.125   |   0.606   ||   1.511   |  0.453  \n",
      " 10/ 10 ||    1.072   |   0.576   ||   1.483   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.7 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.4 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.892   |   0.247   ||   1.876   |  0.283  \n",
      " 2 / 10 ||    1.419   |   0.535   ||   1.669   |  0.283  \n",
      " 3 / 10 ||    0.954   |   0.689   ||   1.759   |  0.340  \n",
      " 4 / 10 ||    0.759   |   0.760   ||   1.886   |  0.340  \n",
      " 5 / 10 ||    0.568   |   0.816   ||   1.773   |  0.302  \n",
      " 6 / 10 ||    0.488   |   0.839   ||   1.936   |  0.340  \n",
      " 7 / 10 ||    0.401   |   0.894   ||   2.099   |  0.358  \n",
      " 8 / 10 ||    0.343   |   0.892   ||   2.222   |  0.321  \n",
      " 9 / 10 ||    0.311   |   0.916   ||   2.200   |  0.321  \n",
      " 10/ 10 ||    0.245   |   0.942   ||   2.455   |  0.321  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.924   |   0.252   ||   1.908   |  0.226  \n",
      " 2 / 10 ||    1.710   |   0.490   ||   1.755   |  0.358  \n",
      " 3 / 10 ||    1.262   |   0.588   ||   1.545   |  0.434  \n",
      " 4 / 10 ||    0.989   |   0.674   ||   1.405   |  0.396  \n",
      " 5 / 10 ||    0.809   |   0.729   ||   1.448   |  0.434  \n",
      " 6 / 10 ||    0.698   |   0.772   ||   1.396   |  0.434  \n",
      " 7 / 10 ||    0.595   |   0.814   ||   1.496   |  0.415  \n",
      " 8 / 10 ||    0.535   |   0.838   ||   1.578   |  0.472  \n",
      " 9 / 10 ||    0.522   |   0.829   ||   1.791   |  0.434  \n",
      " 10/ 10 ||    0.485   |   0.829   ||   1.715   |  0.453  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.5 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.812   |   0.348   ||   1.839   |  0.226  \n",
      " 2 / 10 ||    1.213   |   0.582   ||   1.780   |  0.321  \n",
      " 3 / 10 ||    0.872   |   0.725   ||   1.808   |  0.302  \n",
      " 4 / 10 ||    0.684   |   0.787   ||   1.864   |  0.377  \n",
      " 5 / 10 ||    0.569   |   0.812   ||   1.900   |  0.396  \n",
      " 6 / 10 ||    0.511   |   0.841   ||   1.912   |  0.396  \n",
      " 7 / 10 ||    0.439   |   0.856   ||   2.088   |  0.377  \n",
      " 8 / 10 ||    0.358   |   0.891   ||   2.103   |  0.358  \n",
      " 9 / 10 ||    0.317   |   0.904   ||   2.234   |  0.340  \n",
      " 10/ 10 ||    0.296   |   0.908   ||   2.206   |  0.321  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.4 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.941   |   0.132   ||   1.933   |  0.283  \n",
      " 2 / 10 ||    1.918   |   0.228   ||   1.934   |  0.283  \n",
      " 3 / 10 ||    1.879   |   0.341   ||   1.919   |  0.151  \n",
      " 4 / 10 ||    1.739   |   0.497   ||   1.905   |  0.226  \n",
      " 5 / 10 ||    1.534   |   0.551   ||   1.894   |  0.208  \n",
      " 6 / 10 ||    1.288   |   0.581   ||   1.847   |  0.264  \n",
      " 7 / 10 ||    1.043   |   0.665   ||   1.868   |  0.245  \n",
      " 8 / 10 ||    0.892   |   0.701   ||   1.945   |  0.264  \n",
      " 9 / 10 ||    0.784   |   0.772   ||   2.039   |  0.283  \n",
      " 10/ 10 ||    0.683   |   0.814   ||   2.012   |  0.264  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.939   |   0.185   ||   1.933   |  0.226  \n",
      " 2 / 10 ||    1.829   |   0.488   ||   1.891   |  0.245  \n",
      " 3 / 10 ||    1.405   |   0.685   ||   1.726   |  0.245  \n",
      " 4 / 10 ||    0.909   |   0.738   ||   1.714   |  0.226  \n",
      " 5 / 10 ||    0.623   |   0.823   ||   1.715   |  0.283  \n",
      " 6 / 10 ||    0.463   |   0.908   ||   1.726   |  0.245  \n",
      " 7 / 10 ||    0.394   |   0.865   ||   1.835   |  0.302  \n",
      " 8 / 10 ||    0.291   |   0.935   ||   1.771   |  0.340  \n",
      " 9 / 10 ||    0.252   |   0.931   ||   2.054   |  0.302  \n",
      " 10/ 10 ||    0.231   |   0.946   ||   2.047   |  0.340  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.943   |   0.174   ||   1.959   |  0.151  \n",
      " 2 / 10 ||    1.930   |   0.208   ||   1.949   |  0.151  \n",
      " 3 / 10 ||    1.894   |   0.258   ||   1.892   |  0.226  \n",
      " 4 / 10 ||    1.832   |   0.369   ||   1.848   |  0.302  \n",
      " 5 / 10 ||    1.697   |   0.369   ||   1.745   |  0.340  \n",
      " 6 / 10 ||    1.505   |   0.411   ||   1.643   |  0.415  \n",
      " 7 / 10 ||    1.369   |   0.504   ||   1.549   |  0.396  \n",
      " 8 / 10 ||    1.259   |   0.564   ||   1.522   |  0.377  \n",
      " 9 / 10 ||    1.154   |   0.619   ||   1.558   |  0.377  \n",
      " 10/ 10 ||    1.068   |   0.665   ||   1.440   |  0.415  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.897   |   0.247   ||   1.900   |  0.208  \n",
      " 2 / 10 ||    1.463   |   0.468   ||   1.804   |  0.358  \n",
      " 3 / 10 ||    1.044   |   0.665   ||   1.765   |  0.358  \n",
      " 4 / 10 ||    0.822   |   0.729   ||   1.773   |  0.396  \n",
      " 5 / 10 ||    0.652   |   0.808   ||   1.833   |  0.358  \n",
      " 6 / 10 ||    0.550   |   0.823   ||   1.954   |  0.377  \n",
      " 7 / 10 ||    0.467   |   0.852   ||   2.005   |  0.396  \n",
      " 8 / 10 ||    0.382   |   0.882   ||   2.129   |  0.302  \n",
      " 9 / 10 ||    0.345   |   0.897   ||   2.149   |  0.302  \n",
      " 10/ 10 ||    0.267   |   0.921   ||   2.138   |  0.358  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 4.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.927   |   0.213   ||   1.885   |  0.377  \n",
      " 2 / 10 ||    1.649   |   0.454   ||   1.611   |  0.472  \n",
      " 3 / 10 ||    1.190   |   0.601   ||   1.537   |  0.415  \n",
      " 4 / 10 ||    0.935   |   0.687   ||   1.313   |  0.491  \n",
      " 5 / 10 ||    0.803   |   0.731   ||   1.394   |  0.453  \n",
      " 6 / 10 ||    0.689   |   0.774   ||   1.348   |  0.434  \n",
      " 7 / 10 ||    0.622   |   0.814   ||   1.444   |  0.453  \n",
      " 8 / 10 ||    0.581   |   0.821   ||   1.573   |  0.453  \n",
      " 9 / 10 ||    0.533   |   0.817   ||   1.582   |  0.453  \n",
      " 10/ 10 ||    0.473   |   0.840   ||   1.561   |  0.453  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.822   |   0.324   ||   1.878   |  0.264  \n",
      " 2 / 10 ||    1.241   |   0.580   ||   1.864   |  0.264  \n",
      " 3 / 10 ||    0.900   |   0.708   ||   1.748   |  0.396  \n",
      " 4 / 10 ||    0.730   |   0.767   ||   1.772   |  0.377  \n",
      " 5 / 10 ||    0.604   |   0.816   ||   1.919   |  0.415  \n",
      " 6 / 10 ||    0.490   |   0.848   ||   1.891   |  0.358  \n",
      " 7 / 10 ||    0.432   |   0.864   ||   1.869   |  0.396  \n",
      " 8 / 10 ||    0.381   |   0.892   ||   2.231   |  0.358  \n",
      " 9 / 10 ||    0.353   |   0.894   ||   2.013   |  0.396  \n",
      " 10/ 10 ||    0.289   |   0.919   ||   2.175   |  0.340  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.946   |   0.162   ||   1.933   |  0.283  \n",
      " 2 / 10 ||    1.924   |   0.257   ||   1.925   |  0.245  \n",
      " 3 / 10 ||    1.874   |   0.389   ||   1.917   |  0.208  \n",
      " 4 / 10 ||    1.718   |   0.539   ||   1.879   |  0.151  \n",
      " 5 / 10 ||    1.478   |   0.509   ||   1.876   |  0.170  \n",
      " 6 / 10 ||    1.234   |   0.605   ||   1.858   |  0.151  \n",
      " 7 / 10 ||    1.056   |   0.695   ||   1.804   |  0.170  \n",
      " 8 / 10 ||    0.890   |   0.731   ||   1.850   |  0.170  \n",
      " 9 / 10 ||    0.730   |   0.760   ||   1.894   |  0.189  \n",
      " 10/ 10 ||    0.648   |   0.802   ||   1.897   |  0.283  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.931   |   0.212   ||   1.937   |  0.321  \n",
      " 2 / 10 ||    1.807   |   0.431   ||   1.883   |  0.377  \n",
      " 3 / 10 ||    1.424   |   0.627   ||   1.779   |  0.377  \n",
      " 4 / 10 ||    0.982   |   0.731   ||   1.645   |  0.415  \n",
      " 5 / 10 ||    0.723   |   0.804   ||   1.549   |  0.453  \n",
      " 6 / 10 ||    0.529   |   0.854   ||   1.450   |  0.415  \n",
      " 7 / 10 ||    0.444   |   0.892   ||   1.491   |  0.396  \n",
      " 8 / 10 ||    0.331   |   0.931   ||   1.429   |  0.491  \n",
      " 9 / 10 ||    0.248   |   0.935   ||   1.531   |  0.472  \n",
      " 10/ 10 ||    0.209   |   0.962   ||   1.583   |  0.434  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.948   |   0.127   ||   1.939   |  0.151  \n",
      " 2 / 10 ||    1.935   |   0.157   ||   1.928   |  0.151  \n",
      " 3 / 10 ||    1.902   |   0.191   ||   1.907   |  0.151  \n",
      " 4 / 10 ||    1.804   |   0.258   ||   1.850   |  0.245  \n",
      " 5 / 10 ||    1.662   |   0.394   ||   1.758   |  0.283  \n",
      " 6 / 10 ||    1.528   |   0.441   ||   1.699   |  0.321  \n",
      " 7 / 10 ||    1.373   |   0.508   ||   1.589   |  0.264  \n",
      " 8 / 10 ||    1.295   |   0.521   ||   1.585   |  0.283  \n",
      " 9 / 10 ||    1.170   |   0.610   ||   1.587   |  0.302  \n",
      " 10/ 10 ||    1.115   |   0.623   ||   1.573   |  0.377  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.9 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.897   |   0.269   ||   1.896   |  0.358  \n",
      " 2 / 10 ||    1.411   |   0.524   ||   1.764   |  0.283  \n",
      " 3 / 10 ||    1.014   |   0.648   ||   1.801   |  0.302  \n",
      " 4 / 10 ||    0.771   |   0.768   ||   1.846   |  0.321  \n",
      " 5 / 10 ||    0.639   |   0.805   ||   1.920   |  0.358  \n",
      " 6 / 10 ||    0.514   |   0.848   ||   2.010   |  0.283  \n",
      " 7 / 10 ||    0.408   |   0.889   ||   2.016   |  0.302  \n",
      " 8 / 10 ||    0.362   |   0.887   ||   2.122   |  0.302  \n",
      " 9 / 10 ||    0.311   |   0.910   ||   2.287   |  0.283  \n",
      " 10/ 10 ||    0.252   |   0.927   ||   2.317   |  0.321  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.6 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.926   |   0.262   ||   1.901   |  0.264  \n",
      " 2 / 10 ||    1.680   |   0.473   ||   1.749   |  0.321  \n",
      " 3 / 10 ||    1.197   |   0.614   ||   1.666   |  0.358  \n",
      " 4 / 10 ||    0.932   |   0.697   ||   1.578   |  0.396  \n",
      " 5 / 10 ||    0.778   |   0.744   ||   1.727   |  0.434  \n",
      " 6 / 10 ||    0.697   |   0.768   ||   1.654   |  0.453  \n",
      " 7 / 10 ||    0.588   |   0.800   ||   1.608   |  0.415  \n",
      " 8 / 10 ||    0.587   |   0.800   ||   1.881   |  0.453  \n",
      " 9 / 10 ||    0.491   |   0.821   ||   1.827   |  0.453  \n",
      " 10/ 10 ||    0.472   |   0.847   ||   2.028   |  0.453  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.816   |   0.328   ||   1.937   |  0.113  \n",
      " 2 / 10 ||    1.252   |   0.570   ||   1.841   |  0.245  \n",
      " 3 / 10 ||    0.915   |   0.690   ||   1.880   |  0.358  \n",
      " 4 / 10 ||    0.705   |   0.764   ||   1.842   |  0.340  \n",
      " 5 / 10 ||    0.622   |   0.816   ||   1.944   |  0.396  \n",
      " 6 / 10 ||    0.493   |   0.858   ||   2.064   |  0.377  \n",
      " 7 / 10 ||    0.443   |   0.857   ||   2.069   |  0.377  \n",
      " 8 / 10 ||    0.389   |   0.887   ||   2.016   |  0.396  \n",
      " 9 / 10 ||    0.343   |   0.903   ||   2.085   |  0.396  \n",
      " 10/ 10 ||    0.298   |   0.911   ||   2.456   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 11.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.6 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.945   |   0.156   ||   1.958   |  0.132  \n",
      " 2 / 10 ||    1.917   |   0.257   ||   1.950   |  0.283  \n",
      " 3 / 10 ||    1.863   |   0.401   ||   1.925   |  0.170  \n",
      " 4 / 10 ||    1.705   |   0.467   ||   1.910   |  0.151  \n",
      " 5 / 10 ||    1.519   |   0.521   ||   1.890   |  0.132  \n",
      " 6 / 10 ||    1.270   |   0.593   ||   1.840   |  0.151  \n",
      " 7 / 10 ||    1.088   |   0.701   ||   1.918   |  0.132  \n",
      " 8 / 10 ||    0.944   |   0.695   ||   1.996   |  0.208  \n",
      " 9 / 10 ||    0.811   |   0.754   ||   2.070   |  0.208  \n",
      " 10/ 10 ||    0.720   |   0.778   ||   2.129   |  0.245  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.4 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.938   |   0.158   ||   1.945   |  0.189  \n",
      " 2 / 10 ||    1.825   |   0.465   ||   1.896   |  0.302  \n",
      " 3 / 10 ||    1.446   |   0.623   ||   1.752   |  0.396  \n",
      " 4 / 10 ||    1.016   |   0.719   ||   1.653   |  0.283  \n",
      " 5 / 10 ||    0.689   |   0.842   ||   1.595   |  0.226  \n",
      " 6 / 10 ||    0.483   |   0.912   ||   1.590   |  0.302  \n",
      " 7 / 10 ||    0.384   |   0.923   ||   1.642   |  0.358  \n",
      " 8 / 10 ||    0.333   |   0.908   ||   1.750   |  0.340  \n",
      " 9 / 10 ||    0.289   |   0.931   ||   1.843   |  0.302  \n",
      " 10/ 10 ||    0.235   |   0.935   ||   1.815   |  0.340  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.5 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.952   |   0.114   ||   1.941   |  0.132  \n",
      " 2 / 10 ||    1.940   |   0.144   ||   1.932   |  0.170  \n",
      " 3 / 10 ||    1.905   |   0.322   ||   1.891   |  0.302  \n",
      " 4 / 10 ||    1.821   |   0.335   ||   1.817   |  0.245  \n",
      " 5 / 10 ||    1.683   |   0.364   ||   1.735   |  0.208  \n",
      " 6 / 10 ||    1.529   |   0.432   ||   1.632   |  0.264  \n",
      " 7 / 10 ||    1.399   |   0.496   ||   1.576   |  0.321  \n",
      " 8 / 10 ||    1.290   |   0.547   ||   1.563   |  0.340  \n",
      " 9 / 10 ||    1.222   |   0.564   ||   1.616   |  0.340  \n",
      " 10/ 10 ||    1.155   |   0.551   ||   1.566   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.9 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.903   |   0.245   ||   1.897   |  0.208  \n",
      " 2 / 10 ||    1.445   |   0.511   ||   1.826   |  0.264  \n",
      " 3 / 10 ||    1.011   |   0.669   ||   1.763   |  0.396  \n",
      " 4 / 10 ||    0.771   |   0.748   ||   1.676   |  0.396  \n",
      " 5 / 10 ||    0.646   |   0.784   ||   1.766   |  0.396  \n",
      " 6 / 10 ||    0.525   |   0.824   ||   1.852   |  0.415  \n",
      " 7 / 10 ||    0.426   |   0.869   ||   1.968   |  0.264  \n",
      " 8 / 10 ||    0.380   |   0.889   ||   2.060   |  0.358  \n",
      " 9 / 10 ||    0.310   |   0.916   ||   2.000   |  0.321  \n",
      " 10/ 10 ||    0.279   |   0.931   ||   2.253   |  0.358  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 4.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.931   |   0.203   ||   1.914   |  0.170  \n",
      " 2 / 10 ||    1.705   |   0.418   ||   1.707   |  0.358  \n",
      " 3 / 10 ||    1.262   |   0.584   ||   1.411   |  0.528  \n",
      " 4 / 10 ||    0.945   |   0.702   ||   1.327   |  0.528  \n",
      " 5 / 10 ||    0.764   |   0.759   ||   1.271   |  0.491  \n",
      " 6 / 10 ||    0.663   |   0.772   ||   1.408   |  0.453  \n",
      " 7 / 10 ||    0.606   |   0.808   ||   1.329   |  0.472  \n",
      " 8 / 10 ||    0.511   |   0.834   ||   1.470   |  0.491  \n",
      " 9 / 10 ||    0.519   |   0.829   ||   1.455   |  0.434  \n",
      " 10/ 10 ||    0.465   |   0.844   ||   1.747   |  0.453  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.836   |   0.310   ||   1.857   |  0.283  \n",
      " 2 / 10 ||    1.199   |   0.624   ||   1.809   |  0.358  \n",
      " 3 / 10 ||    0.900   |   0.708   ||   1.798   |  0.321  \n",
      " 4 / 10 ||    0.656   |   0.795   ||   1.960   |  0.340  \n",
      " 5 / 10 ||    0.578   |   0.803   ||   1.982   |  0.321  \n",
      " 6 / 10 ||    0.492   |   0.850   ||   2.101   |  0.340  \n",
      " 7 / 10 ||    0.419   |   0.858   ||   2.075   |  0.340  \n",
      " 8 / 10 ||    0.365   |   0.890   ||   2.531   |  0.358  \n",
      " 9 / 10 ||    0.319   |   0.893   ||   2.275   |  0.340  \n",
      " 10/ 10 ||    0.286   |   0.913   ||   2.403   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.946   |   0.114   ||   1.953   |  0.075  \n",
      " 2 / 10 ||    1.916   |   0.275   ||   1.942   |  0.151  \n",
      " 3 / 10 ||    1.877   |   0.395   ||   1.939   |  0.170  \n",
      " 4 / 10 ||    1.767   |   0.437   ||   1.910   |  0.189  \n",
      " 5 / 10 ||    1.533   |   0.605   ||   1.894   |  0.208  \n",
      " 6 / 10 ||    1.307   |   0.623   ||   1.923   |  0.226  \n",
      " 7 / 10 ||    1.097   |   0.683   ||   2.002   |  0.189  \n",
      " 8 / 10 ||    0.911   |   0.707   ||   2.017   |  0.189  \n",
      " 9 / 10 ||    0.714   |   0.820   ||   2.129   |  0.226  \n",
      " 10/ 10 ||    0.683   |   0.820   ||   2.153   |  0.321  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.4 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.933   |   0.235   ||   1.930   |  0.208  \n",
      " 2 / 10 ||    1.803   |   0.538   ||   1.879   |  0.415  \n",
      " 3 / 10 ||    1.411   |   0.623   ||   1.773   |  0.321  \n",
      " 4 / 10 ||    0.982   |   0.704   ||   1.601   |  0.434  \n",
      " 5 / 10 ||    0.731   |   0.788   ||   1.580   |  0.396  \n",
      " 6 / 10 ||    0.524   |   0.858   ||   1.549   |  0.358  \n",
      " 7 / 10 ||    0.375   |   0.927   ||   1.497   |  0.377  \n",
      " 8 / 10 ||    0.345   |   0.896   ||   1.555   |  0.415  \n",
      " 9 / 10 ||    0.276   |   0.923   ||   1.600   |  0.377  \n",
      " 10/ 10 ||    0.236   |   0.942   ||   1.644   |  0.415  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.6 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.948   |   0.157   ||   1.944   |  0.189  \n",
      " 2 / 10 ||    1.929   |   0.212   ||   1.939   |  0.226  \n",
      " 3 / 10 ||    1.894   |   0.229   ||   1.890   |  0.283  \n",
      " 4 / 10 ||    1.800   |   0.369   ||   1.832   |  0.358  \n",
      " 5 / 10 ||    1.606   |   0.458   ||   1.730   |  0.302  \n",
      " 6 / 10 ||    1.455   |   0.470   ||   1.605   |  0.302  \n",
      " 7 / 10 ||    1.267   |   0.585   ||   1.609   |  0.358  \n",
      " 8 / 10 ||    1.195   |   0.597   ||   1.583   |  0.358  \n",
      " 9 / 10 ||    1.071   |   0.648   ||   1.561   |  0.358  \n",
      " 10/ 10 ||    1.004   |   0.657   ||   1.450   |  0.434  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.7 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.900   |   0.277   ||   1.923   |  0.170  \n",
      " 2 / 10 ||    1.454   |   0.521   ||   1.800   |  0.226  \n",
      " 3 / 10 ||    0.967   |   0.682   ||   1.685   |  0.415  \n",
      " 4 / 10 ||    0.727   |   0.760   ||   1.765   |  0.340  \n",
      " 5 / 10 ||    0.584   |   0.831   ||   1.723   |  0.340  \n",
      " 6 / 10 ||    0.474   |   0.869   ||   1.812   |  0.358  \n",
      " 7 / 10 ||    0.390   |   0.881   ||   2.002   |  0.358  \n",
      " 8 / 10 ||    0.321   |   0.905   ||   2.018   |  0.358  \n",
      " 9 / 10 ||    0.315   |   0.900   ||   2.075   |  0.321  \n",
      " 10/ 10 ||    0.245   |   0.932   ||   2.137   |  0.283  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 4.1 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.3 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.919   |   0.188   ||   1.890   |  0.302  \n",
      " 2 / 10 ||    1.626   |   0.469   ||   1.578   |  0.396  \n",
      " 3 / 10 ||    1.169   |   0.614   ||   1.365   |  0.453  \n",
      " 4 / 10 ||    0.949   |   0.661   ||   1.366   |  0.415  \n",
      " 5 / 10 ||    0.794   |   0.727   ||   1.345   |  0.453  \n",
      " 6 / 10 ||    0.689   |   0.768   ||   1.274   |  0.434  \n",
      " 7 / 10 ||    0.617   |   0.808   ||   1.389   |  0.453  \n",
      " 8 / 10 ||    0.579   |   0.802   ||   1.548   |  0.434  \n",
      " 9 / 10 ||    0.509   |   0.817   ||   1.529   |  0.434  \n",
      " 10/ 10 ||    0.446   |   0.857   ||   1.643   |  0.453  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.4 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.833   |   0.279   ||   1.883   |  0.151  \n",
      " 2 / 10 ||    1.246   |   0.554   ||   1.866   |  0.283  \n",
      " 3 / 10 ||    0.933   |   0.687   ||   2.014   |  0.245  \n",
      " 4 / 10 ||    0.728   |   0.773   ||   1.939   |  0.302  \n",
      " 5 / 10 ||    0.598   |   0.800   ||   1.897   |  0.358  \n",
      " 6 / 10 ||    0.498   |   0.841   ||   2.213   |  0.358  \n",
      " 7 / 10 ||    0.436   |   0.859   ||   2.005   |  0.377  \n",
      " 8 / 10 ||    0.395   |   0.868   ||   2.123   |  0.396  \n",
      " 9 / 10 ||    0.362   |   0.870   ||   2.140   |  0.340  \n",
      " 10/ 10 ||    0.307   |   0.907   ||   2.246   |  0.358  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 42 batches in 10.4 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'source_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.949   |   0.150   ||   1.968   |  0.075  \n",
      " 2 / 10 ||    1.921   |   0.192   ||   1.953   |  0.075  \n",
      " 3 / 10 ||    1.855   |   0.329   ||   1.927   |  0.094  \n",
      " 4 / 10 ||    1.701   |   0.527   ||   1.889   |  0.189  \n",
      " 5 / 10 ||    1.455   |   0.569   ||   1.848   |  0.226  \n",
      " 6 / 10 ||    1.222   |   0.635   ||   1.864   |  0.283  \n",
      " 7 / 10 ||    1.018   |   0.695   ||   1.863   |  0.264  \n",
      " 8 / 10 ||    0.890   |   0.731   ||   1.798   |  0.302  \n",
      " 9 / 10 ||    0.798   |   0.749   ||   1.822   |  0.264  \n",
      " 10/ 10 ||    0.669   |   0.784   ||   1.961   |  0.302  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 65 batches in 2.2 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'human_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.930   |   0.208   ||   1.929   |  0.321  \n",
      " 2 / 10 ||    1.832   |   0.519   ||   1.896   |  0.264  \n",
      " 3 / 10 ||    1.520   |   0.615   ||   1.756   |  0.415  \n",
      " 4 / 10 ||    1.023   |   0.735   ||   1.715   |  0.415  \n",
      " 5 / 10 ||    0.698   |   0.831   ||   1.609   |  0.321  \n",
      " 6 / 10 ||    0.503   |   0.892   ||   1.678   |  0.283  \n",
      " 7 / 10 ||    0.414   |   0.877   ||   1.809   |  0.302  \n",
      " 8 / 10 ||    0.311   |   0.935   ||   1.752   |  0.283  \n",
      " 9 / 10 ||    0.264   |   0.942   ||   1.900   |  0.283  \n",
      " 10/ 10 ||    0.177   |   0.973   ||   1.908   |  0.302  \n",
      "Dataloader from ('['data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 59 batches in 2.5 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'gpt_data' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.950   |   0.140   ||   1.933   |  0.151  \n",
      " 2 / 10 ||    1.932   |   0.216   ||   1.929   |  0.170  \n",
      " 3 / 10 ||    1.897   |   0.246   ||   1.898   |  0.170  \n",
      " 4 / 10 ||    1.804   |   0.343   ||   1.848   |  0.358  \n",
      " 5 / 10 ||    1.652   |   0.398   ||   1.722   |  0.264  \n",
      " 6 / 10 ||    1.543   |   0.419   ||   1.675   |  0.321  \n",
      " 7 / 10 ||    1.386   |   0.492   ||   1.582   |  0.302  \n",
      " 8 / 10 ||    1.286   |   0.504   ||   1.561   |  0.340  \n",
      " 9 / 10 ||    1.174   |   0.547   ||   1.571   |  0.340  \n",
      " 10/ 10 ||    1.097   |   0.614   ||   1.510   |  0.340  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts']') created with 155 batches in 11.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_human_texts' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.884   |   0.265   ||   1.929   |  0.264  \n",
      " 2 / 10 ||    1.384   |   0.552   ||   1.779   |  0.396  \n",
      " 3 / 10 ||    0.990   |   0.684   ||   1.637   |  0.377  \n",
      " 4 / 10 ||    0.730   |   0.771   ||   1.711   |  0.302  \n",
      " 5 / 10 ||    0.609   |   0.800   ||   1.711   |  0.358  \n",
      " 6 / 10 ||    0.502   |   0.844   ||   1.886   |  0.283  \n",
      " 7 / 10 ||    0.434   |   0.861   ||   1.795   |  0.321  \n",
      " 8 / 10 ||    0.348   |   0.900   ||   2.009   |  0.302  \n",
      " 9 / 10 ||    0.293   |   0.915   ||   1.930   |  0.340  \n",
      " 10/ 10 ||    0.238   |   0.932   ||   2.071   |  0.264  \n",
      "Dataloader from ('['data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 133 batches in 3.8 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.2 seconds.\n",
      "Training model on 'all_summaries' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.925   |   0.220   ||   1.923   |  0.245  \n",
      " 2 / 10 ||    1.679   |   0.510   ||   1.732   |  0.283  \n",
      " 3 / 10 ||    1.252   |   0.601   ||   1.544   |  0.358  \n",
      " 4 / 10 ||    1.007   |   0.655   ||   1.435   |  0.358  \n",
      " 5 / 10 ||    0.843   |   0.712   ||   1.402   |  0.415  \n",
      " 6 / 10 ||    0.756   |   0.755   ||   1.400   |  0.453  \n",
      " 7 / 10 ||    0.656   |   0.774   ||   1.421   |  0.434  \n",
      " 8 / 10 ||    0.598   |   0.812   ||   1.627   |  0.472  \n",
      " 9 / 10 ||    0.573   |   0.804   ||   1.737   |  0.453  \n",
      " 10/ 10 ||    0.522   |   0.832   ||   1.605   |  0.453  \n",
      "Dataloader from ('['data\\\\base_texts', 'data\\\\wikipedia', 'data\\\\philosophize_this_transcripts', 'data\\\\gpt_summaries', 'data\\\\gpt_philosophy_game']') created with 230 batches in 13.7 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 4.4 seconds.\n",
      "Training model on 'all_sources' data split\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.819   |   0.315   ||   1.879   |  0.245  \n",
      " 2 / 10 ||    1.262   |   0.578   ||   1.917   |  0.377  \n",
      " 3 / 10 ||    0.912   |   0.706   ||   1.906   |  0.358  \n",
      " 4 / 10 ||    0.732   |   0.755   ||   1.902   |  0.321  \n",
      " 5 / 10 ||    0.597   |   0.826   ||   2.013   |  0.321  \n",
      " 6 / 10 ||    0.502   |   0.847   ||   1.938   |  0.340  \n",
      " 7 / 10 ||    0.456   |   0.844   ||   2.021   |  0.340  \n",
      " 8 / 10 ||    0.411   |   0.868   ||   2.379   |  0.302  \n",
      " 9 / 10 ||    0.368   |   0.878   ||   2.321   |  0.340  \n",
      " 10/ 10 ||    0.314   |   0.893   ||   2.195   |  0.358  \n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"input_dim\": 384,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"output_dim\": loader_params['num_labels'],\n",
    "    \"dropout\": 0.35\n",
    "}\n",
    "train_params = {\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 1e-3\n",
    "}\n",
    "\n",
    "train_splits = {\n",
    "    \"source_texts\": [\"base_texts\"],\n",
    "    \"human_summaries\": [\"wikipedia\", \"philosophize_this_transcripts\"],\n",
    "    \"gpt_data\": [\"gpt_summaries\", \"gpt_philosophy_game\"],\n",
    "    \"all_human_texts\": [\"base_texts\", \"wikipedia\", \"philosophize_this_transcripts\"],\n",
    "    \"all_summaries\": [\"wikipedia\", \"philosophize_this_transcripts\", \"gpt_summaries\", \"gpt_philosophy_game\"],\n",
    "    \"all_sources\": [\"base_texts\", \"wikipedia\", \"philosophize_this_transcripts\", \"gpt_summaries\", \"gpt_philosophy_game\"],\n",
    "}\n",
    "eval_losses = {\n",
    "    \"source_texts\": [],\n",
    "    \"human_summaries\": [],\n",
    "    \"gpt_data\": [],\n",
    "    \"all_human_texts\": [],\n",
    "    \"all_summaries\": [],\n",
    "    \"all_sources\": [],\n",
    "} \n",
    "\n",
    "test_folders = [\"eval_data\"]\n",
    "filename_category_mapping, category_label_mapping = loader.load_labeling_mappings()\n",
    "\n",
    "for t in range(10):\n",
    "    for data_split, train_folders in train_splits.items():\n",
    "        train_dataloader = loader.get_dataloader(train_folders, loader_params, filename_label_mapping, balance_data=True, print_info=False)\n",
    "        test_dataloader = loader.get_dataloader(test_folders, loader_params, filename_label_mapping, balance_data=False, print_info=False)\n",
    "\n",
    "        model = models.Classifier(**model_params)\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=train_params['learning_rate'])\n",
    "        model.to(device)\n",
    "\n",
    "        print(f\"Training model on '{data_split}' data split\")\n",
    "        print(f\"Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\")\n",
    "        for epoch in range(train_params['epochs']):\n",
    "            train_loss = []\n",
    "            num_correct, num_total = 0, 0\n",
    "            for iter, (embeddings, labels) in enumerate(train_dataloader):\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)        \n",
    "                optim.zero_grad()\n",
    "                logits = model(embeddings)\n",
    "                \n",
    "                loss, correct_preds = utility.compute_loss_preds(logits, labels)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "                num_correct += correct_preds\n",
    "                num_total += labels.shape[0]\n",
    "                train_loss.append(loss.cpu().item())\n",
    "\n",
    "            eval_loss, eval_acc = utility.evaluate_model(model, test_dataloader, device)\n",
    "            train_loss = torch.tensor(train_loss)\n",
    "            print(f\" {epoch+1:<2}/{train_params['epochs']:>3} ||    {train_loss.mean():.3f}   |   {num_correct/num_total:.3f}   ||   {eval_loss:.3f}   |  {eval_acc:.3f}  \")\n",
    "        \n",
    "        eval_losses[data_split].append((eval_loss, eval_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philosophy_oracle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
