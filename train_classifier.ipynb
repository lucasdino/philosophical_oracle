{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our Philosophical Document Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\Desktop\\UCSD\\256\\philosophical_oracle\\philosophy_oracle\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import loader\n",
    "import models\n",
    "import utility\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_category_mapping, category_label_mapping = loader.load_labeling_mappings()\n",
    "filename_label_mapping = filename_category_mapping\n",
    "for key, value in filename_label_mapping.items():\n",
    "    filename_label_mapping[key] = int(category_label_mapping[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader from ('['data\\\\base_texts']') created with 121 batches in 11.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 14 batches in 1.6 seconds.\n",
      "Training model on '2000' chunk size\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.919   |   0.228   ||   1.920   |  0.189  \n",
      " 2 / 10 ||    1.667   |   0.412   ||   1.856   |  0.132  \n",
      " 3 / 10 ||    1.194   |   0.594   ||   1.759   |  0.377  \n",
      " 4 / 10 ||    0.869   |   0.723   ||   1.737   |  0.434  \n",
      " 5 / 10 ||    0.677   |   0.760   ||   1.748   |  0.396  \n",
      " 6 / 10 ||    0.511   |   0.841   ||   2.067   |  0.377  \n",
      " 7 / 10 ||    0.436   |   0.872   ||   1.895   |  0.396  \n",
      " 8 / 10 ||    0.347   |   0.905   ||   2.023   |  0.358  \n",
      " 9 / 10 ||    0.297   |   0.919   ||   2.088   |  0.377  \n",
      " 10/ 10 ||    0.236   |   0.944   ||   2.327   |  0.321  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 45 batches in 5.0 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 11 batches in 1.4 seconds.\n",
      "Training model on '5000' chunk size\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.951   |   0.128   ||   1.946   |  0.143  \n",
      " 2 / 10 ||    1.915   |   0.272   ||   1.936   |  0.167  \n",
      " 3 / 10 ||    1.820   |   0.494   ||   1.924   |  0.119  \n",
      " 4 / 10 ||    1.600   |   0.544   ||   1.907   |  0.119  \n",
      " 5 / 10 ||    1.299   |   0.606   ||   1.847   |  0.310  \n",
      " 6 / 10 ||    1.040   |   0.689   ||   1.798   |  0.357  \n",
      " 7 / 10 ||    0.860   |   0.800   ||   1.680   |  0.357  \n",
      " 8 / 10 ||    0.676   |   0.861   ||   1.634   |  0.405  \n",
      " 9 / 10 ||    0.543   |   0.911   ||   1.622   |  0.429  \n",
      " 10/ 10 ||    0.458   |   0.878   ||   1.614   |  0.381  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 21 batches in 3.1 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 10 batches in 1.4 seconds.\n",
      "Training model on '10000' chunk size\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.941   |   0.120   ||   1.953   |  0.103  \n",
      " 2 / 10 ||    1.923   |   0.265   ||   1.952   |  0.103  \n",
      " 3 / 10 ||    1.899   |   0.361   ||   1.951   |  0.128  \n",
      " 4 / 10 ||    1.855   |   0.398   ||   1.946   |  0.154  \n",
      " 5 / 10 ||    1.757   |   0.542   ||   1.937   |  0.179  \n",
      " 6 / 10 ||    1.624   |   0.590   ||   1.931   |  0.205  \n",
      " 7 / 10 ||    1.486   |   0.602   ||   1.903   |  0.179  \n",
      " 8 / 10 ||    1.316   |   0.663   ||   1.887   |  0.205  \n",
      " 9 / 10 ||    1.165   |   0.747   ||   1.909   |  0.231  \n",
      " 10/ 10 ||    1.042   |   0.759   ||   1.856   |  0.282  \n",
      "Dataloader from ('['data\\\\base_texts']') created with 12 batches in 2.3 seconds.\n",
      "Dataloader from ('['data\\\\eval_data']') created with 10 batches in 1.2 seconds.\n",
      "Training model on '20000' chunk size\n",
      "Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\n",
      " 1 / 10 ||    1.955   |   0.156   ||   1.935   |  0.105  \n",
      " 2 / 10 ||    1.925   |   0.156   ||   1.937   |  0.105  \n",
      " 3 / 10 ||    1.932   |   0.156   ||   1.942   |  0.105  \n",
      " 4 / 10 ||    1.916   |   0.178   ||   1.939   |  0.105  \n",
      " 5 / 10 ||    1.882   |   0.289   ||   1.940   |  0.105  \n",
      " 6 / 10 ||    1.858   |   0.311   ||   1.940   |  0.105  \n",
      " 7 / 10 ||    1.824   |   0.333   ||   1.939   |  0.105  \n",
      " 8 / 10 ||    1.701   |   0.356   ||   1.943   |  0.105  \n",
      " 9 / 10 ||    1.635   |   0.511   ||   1.937   |  0.079  \n",
      " 10/ 10 ||    1.629   |   0.511   ||   1.948   |  0.132  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_size, _ \u001b[38;5;129;01min\u001b[39;00m eval_losses\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     42\u001b[0m     loader_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(chunk_size)\n\u001b[1;32m---> 43\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_folders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_label_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalance_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     test_dataloader \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget_dataloader(test_folders, loader_params, filename_label_mapping, balance_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, print_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m     model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n",
      "File \u001b[1;32mc:\\Users\\lucas\\Desktop\\UCSD\\256\\philosophical_oracle\\loader\\dataloader.py:156\u001b[0m, in \u001b[0;36mget_dataloader\u001b[1;34m(data_folders, hyperparams, label_mapping, balance_data, print_info)\u001b[0m\n\u001b[0;32m    154\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    155\u001b[0m data_folders \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, folder) \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m data_folders]\n\u001b[1;32m--> 156\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_embed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunk_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunk_overlap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m balance_data:\n\u001b[0;32m    158\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m balance_dataset(dataframe, label_mapping, max_multiplier\u001b[38;5;241m=\u001b[39mhyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalance_multiplier\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\lucas\\Desktop\\UCSD\\256\\philosophical_oracle\\loader\\dataloader.py:38\u001b[0m, in \u001b[0;36mload_and_embed_texts\u001b[1;34m(folders, chunk_size, chunk_overlap, print_info)\u001b[0m\n\u001b[0;32m     36\u001b[0m     text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     37\u001b[0m chunks \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit_text(text)\n\u001b[1;32m---> 38\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunks, embeddings):\n\u001b[0;32m     41\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(embedding),\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: chunk,\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: filename\n\u001b[0;32m     45\u001b[0m     })\n",
      "File \u001b[1;32mc:\\Users\\lucas\\Desktop\\UCSD\\256\\philosophical_oracle\\philosophy_oracle\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader_params = {\n",
    "    \"num_labels\": len(category_label_mapping),\n",
    "    \"batch_size\": 4,\n",
    "    \"chunk_size\": 2000,\n",
    "    \"chunk_overlap\": 100,\n",
    "    \"balance_multiplier\": 1.5,\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"input_dim\": 384,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"output_dim\": loader_params['num_labels'],\n",
    "    \"dropout\": 0.35\n",
    "}\n",
    "train_params = {\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 1e-3\n",
    "}\n",
    "\n",
    "# train_splits = {\n",
    "    # \"source_texts\": [\"base_texts\"],\n",
    "    # \"human_summaries\": [\"wikipedia\", \"philosophize_this_transcripts\"],\n",
    "    # \"gpt_data\": [\"gpt_summaries\", \"gpt_philosophy_game\"],\n",
    "    # \"all_human_texts\": [\"base_texts\", \"wikipedia\", \"philosophize_this_transcripts\"],\n",
    "    # \"all_summaries\": [\"wikipedia\", \"philosophize_this_transcripts\", \"gpt_summaries\", \"gpt_philosophy_game\"],\n",
    "    # \"all_sources\": [\"base_texts\", \"wikipedia\", \"philosophize_this_transcripts\", \"gpt_summaries\", \"gpt_philosophy_game\"],\n",
    "# }\n",
    "\n",
    "eval_losses = {\n",
    "    \"2000\": [],\n",
    "    \"5000\": [],\n",
    "    \"8000\": [],\n",
    "} \n",
    "\n",
    "train_folders = [\"base_texts\"]\n",
    "test_folders = [\"eval_data\"]\n",
    "filename_category_mapping, category_label_mapping = loader.load_labeling_mappings()\n",
    "\n",
    "for t in range(10):\n",
    "    for chunk_size, _ in eval_losses.items():\n",
    "        loader_params['chunk_size'] = int(chunk_size)\n",
    "        train_dataloader = loader.get_dataloader(train_folders, loader_params, filename_label_mapping, balance_data=True, print_info=False)\n",
    "        test_dataloader = loader.get_dataloader(test_folders, loader_params, filename_label_mapping, balance_data=False, print_info=False)\n",
    "\n",
    "        model = models.Classifier(**model_params)\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=train_params['learning_rate'])\n",
    "        model.to(device)\n",
    "\n",
    "        print(f\"Training model on '{chunk_size}' chunk size\")\n",
    "        print(f\"Epochs  || Train Loss | Train Acc || Test Loss | Test Acc\")\n",
    "        for epoch in range(train_params['epochs']):\n",
    "            train_loss = []\n",
    "            num_correct, num_total = 0, 0\n",
    "            for iter, (embeddings, labels) in enumerate(train_dataloader):\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)        \n",
    "                optim.zero_grad()\n",
    "                logits = model(embeddings)\n",
    "                \n",
    "                loss, correct_preds = utility.compute_loss_preds(logits, labels)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "                num_correct += correct_preds\n",
    "                num_total += labels.shape[0]\n",
    "                train_loss.append(loss.cpu().item())\n",
    "\n",
    "            eval_loss, eval_acc = utility.evaluate_model(model, test_dataloader, device)\n",
    "            train_loss = torch.tensor(train_loss)\n",
    "            print(f\" {epoch+1:<2}/{train_params['epochs']:>3} ||    {train_loss.mean():.3f}   |   {num_correct/num_total:.3f}   ||   {eval_loss:.3f}   |  {eval_acc:.3f}  \")\n",
    "        \n",
    "        eval_losses[chunk_size].append((eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to results\\eval_losses_chunksize.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "results_folder = \"results\"\n",
    "output_file = os.path.join(results_folder, \"eval_losses_sourcetexts_chunksize.pkl\")\n",
    "\n",
    "# Save the dictionary to the file\n",
    "with open(output_file, 'wb') as file:\n",
    "    pickle.dump(eval_losses, file)\n",
    "print(f\"Dictionary saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philosophy_oracle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
